{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import multiprocessing as mp\n",
    "from sys import argv\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm\n",
    "from pytorch_lightning.loggers import NeptuneLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5EncoderModel\n",
    "from transformers import AdamW\n",
    "\n",
    "\n",
    "from Datasets import WikiTable, WikiTableText, SquadDataset, Modes\n",
    "from metrics import compute_exact, compute_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNTransformer(pl.LightningModule):\n",
    "    \"\"\"\n",
    "        Class for combinining Vision and Language embeddings for generating answers in VQA Task\n",
    "    \"\"\"\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        \n",
    "        #Parameters stored in dictionary\n",
    "        self.hparams = hparams\n",
    "        \n",
    "        #Tokenizer for decoding sentences\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(self.hparams.t5_model)\n",
    "        \n",
    "        #Decoder -> Decode image embedding combined with the last hidden state of the encoder\n",
    "        self.decoder = T5ForConditionalGeneration.from_pretrained(self.hparams.t5_model)\n",
    "        \n",
    "        #Sentence encoder -> just transformer encoder for questions\n",
    "        if self.hparams.same_enc:\n",
    "            self.sentence_encoder = self.decoder.get_encoder()\n",
    "        else:\n",
    "            self.sentence_encoder = T5EncoderModel.from_pretrained(self.hparams.t5_model)\n",
    "        \n",
    "        self.sync_dist = self.hparams.gpus > 1\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        input_ids = batch['input_ids']\n",
    "        input_attn_mask = batch['input_attn_mask']\n",
    "        questions = batch['question']\n",
    "        answers = batch['answer']\n",
    "        target_ids = batch['target_ids']\n",
    "        \n",
    "        \n",
    "        #obtain the sentence encoder outputs\n",
    "        encoder_outputs = self.sentence_encoder(input_ids=input_ids,\n",
    "                                                attention_mask=input_attn_mask,\n",
    "                                                output_attentions=self.hparams.use_enc_attn)\n",
    "        \n",
    "        #batch size x seqlen x self.d_model\n",
    "        encoder_hidden_state = encoder_outputs.last_hidden_state\n",
    "        \n",
    "        #perhaps use attention coming from the sentence encoder\n",
    "        encoder_attn = encoder_outputs.attentions if self.hparams.use_enc_attn else None \n",
    "    \n",
    "        if self.training:\n",
    "            loss = self.decoder(encoder_outputs=(encoder_hidden_state, encoder_attn),\n",
    "                                labels=target_ids).loss\n",
    "            \n",
    "            return loss\n",
    "        else:\n",
    "            \n",
    "            return self.generate_predictions(hiddn_states=encoder_hidden_state,\n",
    "                                             encoder_attentions=encoder_attn)\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self(batch)\n",
    "        \n",
    "        self.log('loss', torch.Tensor([loss]).to(self.device), on_epoch=True, \n",
    "                 on_step=True, prog_bar=True, sync_dist=self.sync_dist)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def generate_predictions(self, hiddn_states, encoder_attentions=None):\n",
    "        '''\n",
    "        Adaptação de código da aula 10 do semestre passado.\n",
    "        Usa features construídas externamente para gerar frases com T5.\n",
    "        '''\n",
    "        #max len for generated sequence\n",
    "        max_seq_len = self.hparams.max_decod_len\n",
    "        \n",
    "        #decoded ids. Initial tokens for decoding for each batch\n",
    "        decoded_ids = torch.full((hiddn_states.size(0), 1),\n",
    "                                 self.decoder.config.decoder_start_token_id,\n",
    "                                 dtype=torch.long).to(hiddn_states.device)\n",
    "        \n",
    "        #combined hidden states (image + text)\n",
    "        encoder_hidden_states = hiddn_states\n",
    "        \n",
    "        #decoding time!\n",
    "        for step in range(max_seq_len):\n",
    "            #get the next token id given the ones decoded so far\n",
    "            outputs = self.decoder(decoder_input_ids=decoded_ids,\n",
    "                                  encoder_outputs=(encoder_hidden_states, encoder_attentions),\n",
    "                                  return_dict=True)\n",
    "            #take the logits\n",
    "            logits = outputs[\"logits\"]\n",
    "            \n",
    "            #get last logits\n",
    "            next_token_logits = logits[:, -1, :]\n",
    "\n",
    "            # Greedy decoding\n",
    "            next_token_id = next_token_logits.argmax(1).unsqueeze(-1)\n",
    "\n",
    "            # Check if output is end of senquence for all batches\n",
    "            if torch.eq(next_token_id[:, -1], self.tokenizer.eos_token_id).all():\n",
    "                break\n",
    "\n",
    "            # Concatenate past ids with new id, keeping batch dimension\n",
    "            decoded_ids = torch.cat([decoded_ids, next_token_id], dim=-1)\n",
    "\n",
    "        return decoded_ids\n",
    "    \n",
    "    \n",
    "    def evaluation_step(self, batch):\n",
    "        '''\n",
    "        Same step for validation and testing.\n",
    "        '''\n",
    "        #get the predictions\n",
    "        pred_tokens = self(batch)\n",
    "        preds = self.tokenizer.batch_decode(pred_tokens, skip_special_tokens=True) \n",
    "\n",
    "        return batch[\"answer\"], preds\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.evaluation_step(batch)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.evaluation_step(batch)\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        return self.epoch_end(outputs, \"val\")\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        return self.epoch_end(outputs, \"test\")\n",
    "    \n",
    "    def epoch_end(self, outputs, step):\n",
    "        tgts, preds = [], []\n",
    "        for output in outputs:\n",
    "            tgts += output[0]\n",
    "            preds += output[1]\n",
    "\n",
    "        f1s, exacts = [], []\n",
    "        for tgt, pred in zip(tgts, preds):\n",
    "            f1s.append(compute_f1(tgt, pred))\n",
    "            exacts.append(compute_exact(tgt, pred))\n",
    "        if self.hparams.debug:\n",
    "            print(f\"Preds: {preds}\")\n",
    "            print(f\"Real: {tgts}\")\n",
    "        else:\n",
    "            self.logger.experiment.log_text(\"Outputs\", f\"Preds: {preds[-10:]} \\n Real: {tgts[-10:]} \\n\\n\")\n",
    "\n",
    "        \n",
    "        self.log(f\"f1_{step}\", torch.Tensor([np.array(f1s).mean()]).to(self.device),\n",
    "                 prog_bar=True, on_step=False, on_epoch=True, sync_dist=self.sync_dist)\n",
    "        \n",
    "        self.log(f\"{step}_exact_match\", torch.Tensor([np.array(exacts).mean()]).to(self.device),\n",
    "                 prog_bar=True, on_step=False, on_epoch=True, sync_dist=self.sync_dist)\n",
    "         \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        ds = None\n",
    "        if self.hparams.pretrain:\n",
    "            print(f\"Pretrainig using {self.hparams.squad} - Train\")\n",
    "            ds = SquadDataset(Modes.TRAIN, self.tokenizer, self.hparams.squad, max_len=self.hparams.seq_len)\n",
    "        else:\n",
    "            ds = WikiTableText(Modes.TRAIN, self.tokenizer, max_len=self.hparams.seq_len)\n",
    "            print(f\"Training using {ds.__class__.__name__}\")\n",
    "        return DataLoader(ds, batch_size=self.hparams.batch_size, shuffle=True, num_workers=self.hparams.nworkers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        ds = None\n",
    "        if self.hparams.pretrain:\n",
    "            ds = SquadDataset(Modes.VAL, self.tokenizer, self.hparams.squad, max_len=self.hparams.seq_len)\n",
    "            print(f\"Pretrainig using {self.hparams.squad} - Valid\")\n",
    "        else:\n",
    "            ds = WikiTableText(Modes.VAL, self.tokenizer, max_len=self.hparams.seq_len)\n",
    "            print(f\"Validating with {ds.__class__.__name__}\")\n",
    "        return DataLoader(ds, batch_size=self.hparams.batch_size, shuffle=False, num_workers=self.hparams.nworkers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        ds = None\n",
    "        if self.hparams.pretrain:\n",
    "            print(f\"Pretrainig using {self.hparams.squad} - Test\")\n",
    "            ds = SquadDataset(Modes.TEST, self.tokenizer, self.hparams.squad, max_len=self.hparams.seq_len)\n",
    "        else:\n",
    "            ds = WikiTableText(Modes.TEST, self.tokenizer, max_len=self.hparams.seq_len)\n",
    "            print(f\"Testing with {ds.__class__.__name__}\")\n",
    "        return DataLoader(ds, batch_size=self.hparams.batch_size, shuffle=False, num_workers=self.hparams.nworkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--pretrain\", action='store_true', help=\"Pretrain or Train\")\n",
    "    parser.add_argument(\"--t5_model\", type=str, default=\"t5-base\", help=\"T5 weights to load.\")\n",
    "    parser.add_argument(\"--seq_len\", type=int, default=128, help=\"Transformer sequence length.\")\n",
    "    parser.add_argument(\"--max_decod_len\", type=int, default=64, help=\"Fast dev run mode.\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=5e-4, help=\"ADAM Learning Rate.\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=2, help=\"Batch size.\")\n",
    "    parser.add_argument(\"--gpus\", type=int, default=1, help=\"Number of GPUs.\")\n",
    "    parser.add_argument(\"--acum\", type=int, default=1, help=\"Acum for batch.\")\n",
    "    parser.add_argument(\"--precision\", type=int, default=32, help=\"Precision.\")\n",
    "    parser.add_argument(\"--max_epochs\", type=int, default=10, help=\"Maximum number of epochs.\")\n",
    "    parser.add_argument(\"--patience\", type=int, default=2, help=\"How many epochs to wait for improvement in validation.\")\n",
    "    parser.add_argument(\"--nworkers\", type=int, default=mp.cpu_count(), help=\"Number of workers to use in dataloading.\")\n",
    "    parser.add_argument(\"--experiment_name\", type=str, default=\"baseline\", help=\"Single word describing experiment.\")\n",
    "    parser.add_argument(\"--description\", type=str, default=\"No description.\", help=\"Single phrase describing experiment.\")\n",
    "    parser.add_argument(\"--use-enc-attn\", action=\"store_true\", help=\"Use Encoder Attention during decoding\")\n",
    "    parser.add_argument(\"--same-enc\", action=\"store_true\", help=\"Use separe encoder and decoder or not\")\n",
    "    parser.add_argument(\"--debug\", action=\"store_true\", help=\"Fast dev run mode.\")\n",
    "    parser.add_argument(\"--load\", type=str, default=None, help=\"Pre trained model to start with.\")\n",
    "    parser.add_argument(\"--accelerator\", type=str, default='ddp', help=\"Multiple GPUs Accelerator\")\n",
    "    parser.add_argument(\"--cpu\", action=\"store_true\", help=\"Force using CPU.\")\n",
    "    \n",
    "    #uncommend if running through CLI\n",
    "    hparams = parser.parse_args()\n",
    "    \n",
    "    #uncommend if running through Jupyter\n",
    "#     hparams = parser.parse_args([])\n",
    "    \n",
    "    print(\"Hyperparameters\")\n",
    "    for k, v in vars(hparams).items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    \n",
    "    if hparams.debug:\n",
    "        logger = False\n",
    "        callbacks = None\n",
    "    else:\n",
    "        logger = NeptuneLogger(api_key=os.getenv('NEPTUNE_API_TOKEN'),\n",
    "                               project_name=\"levy.gurgel/wikitable\",\n",
    "                               experiment_name=hparams.experiment_name,\n",
    "                               tags=[hparams.description],\n",
    "                               params=vars(hparams))\n",
    "        \n",
    "        dir_path = os.path.join(\"models\", hparams.experiment_name)\n",
    "        filename = \"{epoch}-{val_exact_match:.2f}-{f1_val:.2f}-same\"\n",
    "        callbacks = [ModelCheckpoint(prefix=hparams.experiment_name,\n",
    "                                     dirpath=dir_path,\n",
    "                                     filename=filename,\n",
    "                                     monitor=\"f1_val\",\n",
    "                                     mode=\"max\")]\n",
    "    \n",
    "    model = CNNTransformer(hparams=hparams)\n",
    "\n",
    "    trainer = pl.Trainer(max_epochs=hparams.max_epochs,\n",
    "                                 gpus=0 if hparams.cpu else hparams.gpus,\n",
    "                                 accumulate_grad_batches=hparams.acum,\n",
    "                                 precision=hparams.precision,\n",
    "                                 fast_dev_run=hparams.debug,\n",
    "                                 logger=logger,\n",
    "                                 callbacks=callbacks,\n",
    "                                 checkpoint_callback=False if hparams.debug else True,\n",
    "                                 accelerator=None if hparams.gpus <= 1 else hparams.accelerator\n",
    "                                 \n",
    "                        )\n",
    "    trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
